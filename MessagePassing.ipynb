{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b20826a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features data loaded...\n",
      "edge data loaded...\n"
     ]
    }
   ],
   "source": [
    "# Prepare graph data...\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from collections import namedtuple\n",
    "Graph = namedtuple('Graph', ['X', 'Ri', 'Ro', 'y'])\n",
    "class GraphDataset():\n",
    "    def __init__(self, input_dir, n_samples=None):\n",
    "        input_dir = os.path.expandvars(input_dir)\n",
    "        filenames = [os.path.join(input_dir, f) for f in os.listdir(input_dir)\n",
    "                     if f.startswith('event') and f.endswith('.npz')]\n",
    "        self.filenames = (\n",
    "            filenames[:n_samples] if n_samples is not None else filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return load_graph(self.filenames[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "def get_dataset(input_dir,n_files):\n",
    "    return GraphDataset(input_dir, n_files)\n",
    "def load_graph(filename):\n",
    "    graph_dir = os.path.join(os.getcwd(), 'graphs')\n",
    "    # Construct the full path to the specified file\n",
    "    full_path = os.path.join(graph_dir, filename)\n",
    "    \"\"\"Read a single graph NPZ\"\"\"\n",
    "    with np.load(full_path) as f:\n",
    "        return sparse_to_graph(**dict(f.items()))\n",
    "def sparse_to_graph(X, Ri_rows, Ri_cols, Ro_rows, Ro_cols, y, dtype=np.float32):\n",
    "    n_nodes, n_edges = X.shape[0], Ri_rows.shape[0]\n",
    "    Ri = np.zeros((n_nodes, n_edges), dtype=dtype)\n",
    "    Ro = np.zeros((n_nodes, n_edges), dtype=dtype)\n",
    "    Ri[Ri_rows, Ri_cols] = 1\n",
    "    Ro[Ro_rows, Ro_cols] = 1\n",
    "    return Graph(X, Ri, Ro, y)\n",
    "#Function to load X, Ri, Ro, Y.\n",
    "def load_raw(graph_name,xyr):\n",
    "    graph_ex=load_graph(graph_name)\n",
    "    #Load raw data\n",
    "    y=graph_ex.y\n",
    "    Ri=graph_ex.Ri\n",
    "    Ro=graph_ex.Ro\n",
    "    X=graph_ex.X\n",
    "    if xyr=='X':\n",
    "        return X\n",
    "    elif xyr=='Ri':\n",
    "        return Ri\n",
    "    elif xyr=='Ro':\n",
    "        return Ro\n",
    "    else:\n",
    "        return y\n",
    "# Load X data of dimension Nv x 4(including color)\n",
    "import os\n",
    "import pandas as pd\n",
    "dir_ = os.path.join(os.getcwd(), 'color')\n",
    "#dir_ = os.path.join(os.getcwd(), 'coloredX')\n",
    "file_path = os.path.join(dir_, \"event000001000_g000.csv\")\n",
    "v = pd.read_csv(file_path)\n",
    "print(\"features data loaded...\")\n",
    "#Convenient representation of edge data \n",
    "#edges = [[i1,j1], [i2,j2], ... ]; i1, i2,... are outgoing-nodes, and j1, j2, ... are incoming-nodes\n",
    "import json\n",
    "graph='event000001000_g000'\n",
    "with open(\"./networks/\"+graph+\".json\", \"r\") as json_file:\n",
    "        _,_,edges= json.load(json_file)\n",
    "print(\"edge data loaded...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7206730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_name='event000001000_g000.npz'\n",
    "Ri=load_raw(g_name,'Ri')\n",
    "Ro=load_raw(g_name,'Ro')\n",
    "Ri,Ro=Ri.T,Ro.T\n",
    "Rio=Ri+Ro\n",
    "Rio.shape\n",
    "y=load_raw(g_name,'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "363f285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Specify the path to your JSON file\n",
    "json_file_path = 'event000001000_g000_pairs.json'\n",
    "# Open the file and load the JSON data\n",
    "with open(json_file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "# Access the data\n",
    "all_pairs=data[\"all_pairs\"]\n",
    "real_pairs,fake_pairs=data[\"real_pairs\"],data[\"fake_pairs\"]\n",
    "quads,f_quads=data[\"quads\"],data[\"f_quads\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b429ea4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1], [1, 2], [2, 3]]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quads[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b5dbabf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=v[0:4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0465ebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from qiskit.circuit import Parameter\n",
    "# Create a quantum circuit with Nv qubits\n",
    "Nv = 4\n",
    "num_qubits = Nv * 4  # 4 qubits per row (x,y,z,color)\n",
    "#layers=4\n",
    "# Define a list of trainable parameters for the entanglement\n",
    "num_params = Nv  # Number of trainable parameters for the entanglement\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric.nn as geom_nn\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "ansatz = torch.randn(Nv, requires_grad=True)\n",
    "#ansatz = np.random.random(size=(num_params*layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7e4faefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantum_circuit(X,ansatz):\n",
    "    for i in range(Nv):\n",
    "        for j in range(4):\n",
    "            if j==0:\n",
    "                qml.RX(X[i*4+j], wires = i * 4 + j)\n",
    "            elif j==1:\n",
    "                qml.RY(X[i*4+j], wires = i * 4 + j)\n",
    "            else:\n",
    "                qml.RZ(X[i*4+j], wires = i * 4 + j)\n",
    "        #Entangle 3 positions\n",
    "        qml.CNOT(wires = [i * 4, i * 4 + 1])\n",
    "        qml.CNOT(wires = [i * 4 + 1, i * 4 + 2])\n",
    "        qml.CNOT(wires = [i * 4 + 2, i * 4])\n",
    "        #Entangle color and position-x.\n",
    "        qml.CNOT(wires = [i * 4 + 3, i * 4])\n",
    "        # Encode each feature value into a qubit \n",
    "    # Apply trainable entanglement gates\n",
    "    for i in range(Nv):\n",
    "        qml.RZ(ansatz[i], wires = i * 4)\n",
    "    #Fully connect\n",
    "    for i in range(Nv):\n",
    "        for j in range(i + 1, Nv):\n",
    "            # Use trainable parameters for entanglement angles\n",
    "            qml.CNOT(wires = [i * 4, j * 4])\n",
    "# Updated quantum_layer function\n",
    "@qml.qnode(qml.device(\"default.qubit\", wires=4*Nv))\n",
    "def quantum_layer(x,params):\n",
    "    quantum_circuit(x,params)\n",
    "    return [qml.expval(qml.PauliZ(i*4)) for i in range(Nv)]\n",
    "# Create a custom quantum layer with PennyLane\n",
    "class QuantumLayer(nn.Module):\n",
    "    def __init__(self, num_qubits):\n",
    "        super(QuantumLayer, self).__init__()\n",
    "        self.num_qubits = num_qubits\n",
    "    def forward(self, x, params):\n",
    "        return quantum_layer(x,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "53c8dc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2556, 1.3130, 1.3577, 1.3790, 1.4237, 1.4811],\n",
      "       grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class CustomMessagePassingLayer(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(CustomMessagePassingLayer, self).__init__(aggr='add')\n",
    "        self.linear = nn.Linear(in_channels * 2, out_channels)  # Input size is doubled for edge pairs\n",
    "    def forward(self, x, edge_index):\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        return self.propagate(edge_index, x=x)\n",
    "    def message(self, x_i, x_j):\n",
    "        # Concatenate node features for each edge\n",
    "        message = torch.cat([x_i, x_j], dim=1)\n",
    "        return self.linear(message)\n",
    "    def update(self, aggr_out, x):\n",
    "        return aggr_out + x\n",
    "\n",
    "class ClassicalMessagePassing(nn.Module):\n",
    "    def __init__(self, num_nodes, num_edges, num_node_features, num_edge_features):\n",
    "        super(ClassicalMessagePassing, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.edge_classifier = nn.Linear(num_node_features, 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # Classical message passing layer\n",
    "        classical_output = self.message_passing_layer(x.view(self.num_nodes, -1), edge_index)\n",
    "        # Temporary edge features by combining node features (e.g., addition)\n",
    "        temp_edge_features = torch.tensor([])\n",
    "        for i in range(num_nodes):\n",
    "            for j in range(i + 1, num_nodes):\n",
    "                edge_f = classical_output[i] + classical_output[j]\n",
    "                temp_edge_features = torch.cat((temp_edge_features, edge_f.unsqueeze(0)), dim=0)\n",
    "        # Edge-level prediction\n",
    "        edge_scores = self.edge_classifier(temp_edge_features)\n",
    "        return edge_scores.squeeze()\n",
    "\n",
    "# Assuming x and edge_index are your input features and edge connections\n",
    "x = v[0:4].values\n",
    "new_x = torch.tensor(np.delete(x, -1, axis=1)).to(torch.float32)\n",
    "\n",
    "classical_model = ClassicalMessagePassing(num_nodes, num_edges, num_node_features, num_edge_features)\n",
    "classical_output = classical_model(new_x, edge_index)\n",
    "print(classical_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7c83fc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model that integrates quantum and classical components\n",
    "class QuantumMessagePassing(nn.Module):\n",
    "    def __init__(self, num_nodes, num_edges, num_node_features, \n",
    "                 num_edge_features, num_qubits, quantum_params):\n",
    "        super(QuantumMessagePassing, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_edges = num_edges\n",
    "        self.num_node_features = num_node_features\n",
    "        self.num_edge_features = num_edge_features\n",
    "        self.num_qubits = num_qubits\n",
    "        self.quantum_params = quantum_params\n",
    "        self.quantum_layer = QuantumLayer(num_qubits)\n",
    "        self.message_passing_layer = CustomMessagePassingLayer(num_node_features, num_edge_features)\n",
    "        self.edge_temp = nn.Linear(num_node_features, 1)\n",
    "        self.edge_classifier = nn.Linear(num_edge_features, 1)  # Input size is doubled for edge pairs\n",
    "    def forward(self, x, edge_index):\n",
    "        new_x = torch.tensor(np.delete(x, -1, axis=1)).to(torch.float32)\n",
    "        # Classical message passing layer\n",
    "        classical_output = self.message_passing_layer(new_x.view(self.num_nodes, -1), edge_index)\n",
    "        # Temporary edge features by combining node features (e.g., addition)\n",
    "        classical = torch.tensor([])\n",
    "        for i in range(num_nodes):\n",
    "            for j in range(i + 1, num_nodes):\n",
    "                edge_f = classical_output[i] + classical_output[j]\n",
    "                classical = torch.cat((classical, edge_f.unsqueeze(0)), dim=0)\n",
    "        classical_edge_score=(self.edge_temp(classical)).view(1, 6)[0]\n",
    "\n",
    "        # Quantum layer\n",
    "        new_x_q=x.flatten()\n",
    "        quantum_output = self.quantum_layer(new_x_q, self.quantum_params)\n",
    "        \n",
    "        first_q=torch.stack([quantum_output[n] for n in edge_index[0]])\n",
    "        second_q=torch.stack([quantum_output[n] for n in edge_index[1]])\n",
    "        quantum_edge=first_q+second_q\n",
    "    \n",
    "        # Combine quantum and classical outputs for each node in the edge pair\n",
    "        combined_output = quantum_edge+classical_edge_score\n",
    "        combined_output = combined_output.float()\n",
    "        combined_output = combined_output.reshape(6, 1)\n",
    "        # Edge-level prediction\n",
    "        edge_scores = self.edge_classifier(combined_output)\n",
    "        return edge_scores.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e74726c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# Example usage\n",
    "num_nodes = 4\n",
    "num_edges = 6\n",
    "num_node_features = 3\n",
    "num_edge_features = 1  # Scalar edge feature\n",
    "edge_index = torch.tensor([[0, 0, 0, 1, 1, 2], [1, 2, 3, 2, 3, 3]])\n",
    "quantum_params = torch.randn(Nv, requires_grad=True)\n",
    "model = QuantumMessagePassing(num_nodes,num_edges,\n",
    "                              num_node_features,num_edge_features,\n",
    "                              num_qubits, quantum_params)\n",
    "\n",
    "# Assuming x and edge_index are your input features and edge connections\n",
    "edge_index = torch.tensor([[0, 0, 0, 1, 1, 2], \n",
    "                           [1, 2, 3, 2, 3, 3]])  # Fully connected graph\n",
    "\n",
    "output = model(X, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b04e1239",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "3dc190a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.6827016472816467\n",
      "Epoch 2/100, Loss: 0.6826961636543274\n",
      "Epoch 3/100, Loss: 0.6826908588409424\n",
      "Epoch 4/100, Loss: 0.6826856732368469\n",
      "Epoch 5/100, Loss: 0.682680606842041\n",
      "Epoch 6/100, Loss: 0.6826757788658142\n",
      "Epoch 7/100, Loss: 0.6826708316802979\n",
      "Epoch 8/100, Loss: 0.6826660633087158\n",
      "Epoch 9/100, Loss: 0.6826614737510681\n",
      "Epoch 10/100, Loss: 0.6826568245887756\n",
      "Epoch 11/100, Loss: 0.6826522946357727\n",
      "Epoch 12/100, Loss: 0.6826479434967041\n",
      "Epoch 13/100, Loss: 0.6826435923576355\n",
      "Epoch 14/100, Loss: 0.6826391816139221\n",
      "Epoch 15/100, Loss: 0.6826348900794983\n",
      "Epoch 16/100, Loss: 0.682630717754364\n",
      "Epoch 17/100, Loss: 0.682626485824585\n",
      "Epoch 18/100, Loss: 0.6826222538948059\n",
      "Epoch 19/100, Loss: 0.6826181411743164\n",
      "Epoch 20/100, Loss: 0.6826140880584717\n",
      "Epoch 21/100, Loss: 0.682610034942627\n",
      "Epoch 22/100, Loss: 0.6826059818267822\n",
      "Epoch 23/100, Loss: 0.6826019883155823\n",
      "Epoch 24/100, Loss: 0.6825979351997375\n",
      "Epoch 25/100, Loss: 0.6825940012931824\n",
      "Epoch 26/100, Loss: 0.6825900673866272\n",
      "Epoch 27/100, Loss: 0.682586133480072\n",
      "Epoch 28/100, Loss: 0.6825821995735168\n",
      "Epoch 29/100, Loss: 0.6825783252716064\n",
      "Epoch 30/100, Loss: 0.682574450969696\n",
      "Epoch 31/100, Loss: 0.6825706362724304\n",
      "Epoch 32/100, Loss: 0.6825667023658752\n",
      "Epoch 33/100, Loss: 0.6825628280639648\n",
      "Epoch 34/100, Loss: 0.6825590133666992\n",
      "Epoch 35/100, Loss: 0.6825551986694336\n",
      "Epoch 36/100, Loss: 0.682551383972168\n",
      "Epoch 37/100, Loss: 0.6825475692749023\n",
      "Epoch 38/100, Loss: 0.6825437545776367\n",
      "Epoch 39/100, Loss: 0.6825399398803711\n",
      "Epoch 40/100, Loss: 0.6825361251831055\n",
      "Epoch 41/100, Loss: 0.6825323700904846\n",
      "Epoch 42/100, Loss: 0.682528555393219\n",
      "Epoch 43/100, Loss: 0.6825247406959534\n",
      "Epoch 44/100, Loss: 0.6825209259986877\n",
      "Epoch 45/100, Loss: 0.6825172305107117\n",
      "Epoch 46/100, Loss: 0.6825134754180908\n",
      "Epoch 47/100, Loss: 0.6825096607208252\n",
      "Epoch 48/100, Loss: 0.6825059056282043\n",
      "Epoch 49/100, Loss: 0.6825022101402283\n",
      "Epoch 50/100, Loss: 0.6824984550476074\n",
      "Epoch 51/100, Loss: 0.6824946403503418\n",
      "Epoch 52/100, Loss: 0.682490885257721\n",
      "Epoch 53/100, Loss: 0.6824871897697449\n",
      "Epoch 54/100, Loss: 0.6824833750724792\n",
      "Epoch 55/100, Loss: 0.6824796795845032\n",
      "Epoch 56/100, Loss: 0.6824758648872375\n",
      "Epoch 57/100, Loss: 0.6824722290039062\n",
      "Epoch 58/100, Loss: 0.6824684739112854\n",
      "Epoch 59/100, Loss: 0.6824647784233093\n",
      "Epoch 60/100, Loss: 0.6824609637260437\n",
      "Epoch 61/100, Loss: 0.6824572682380676\n",
      "Epoch 62/100, Loss: 0.6824535727500916\n",
      "Epoch 63/100, Loss: 0.6824498176574707\n",
      "Epoch 64/100, Loss: 0.6824460625648499\n",
      "Epoch 65/100, Loss: 0.6824423670768738\n",
      "Epoch 66/100, Loss: 0.6824386119842529\n",
      "Epoch 67/100, Loss: 0.6824348568916321\n",
      "Epoch 68/100, Loss: 0.6824310421943665\n",
      "Epoch 69/100, Loss: 0.6824274659156799\n",
      "Epoch 70/100, Loss: 0.6824237704277039\n",
      "Epoch 71/100, Loss: 0.682420015335083\n",
      "Epoch 72/100, Loss: 0.6824162602424622\n",
      "Epoch 73/100, Loss: 0.6824126243591309\n",
      "Epoch 74/100, Loss: 0.6824089884757996\n",
      "Epoch 75/100, Loss: 0.6824052333831787\n",
      "Epoch 76/100, Loss: 0.6824014782905579\n",
      "Epoch 77/100, Loss: 0.6823977828025818\n",
      "Epoch 78/100, Loss: 0.6823940277099609\n",
      "Epoch 79/100, Loss: 0.6823903918266296\n",
      "Epoch 80/100, Loss: 0.6823866367340088\n",
      "Epoch 81/100, Loss: 0.6823830008506775\n",
      "Epoch 82/100, Loss: 0.6823792457580566\n",
      "Epoch 83/100, Loss: 0.6823756098747253\n",
      "Epoch 84/100, Loss: 0.6823718547821045\n",
      "Epoch 85/100, Loss: 0.6823680996894836\n",
      "Epoch 86/100, Loss: 0.6823644042015076\n",
      "Epoch 87/100, Loss: 0.6823607087135315\n",
      "Epoch 88/100, Loss: 0.6823570728302002\n",
      "Epoch 89/100, Loss: 0.6823533177375793\n",
      "Epoch 90/100, Loss: 0.682349681854248\n",
      "Epoch 91/100, Loss: 0.6823460459709167\n",
      "Epoch 92/100, Loss: 0.6823422908782959\n",
      "Epoch 93/100, Loss: 0.682338535785675\n",
      "Epoch 94/100, Loss: 0.6823348999023438\n",
      "Epoch 95/100, Loss: 0.6823312640190125\n",
      "Epoch 96/100, Loss: 0.6823275089263916\n",
      "Epoch 97/100, Loss: 0.6823238730430603\n",
      "Epoch 98/100, Loss: 0.6823201179504395\n",
      "Epoch 99/100, Loss: 0.6823164820671082\n",
      "Epoch 100/100, Loss: 0.6823127865791321\n"
     ]
    }
   ],
   "source": [
    "# Assuming true_labels is a tensor with true labels for each edge (0 or 1)\n",
    "true_labels = torch.tensor([1, 0, 0, 1, 0, 1], dtype=torch.float32)\n",
    "# Number of training epochs\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    edge_scores = model(X, edge_index)\n",
    "    # Calculate the loss\n",
    "    loss = criterion(edge_scores, true_labels)\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    # Print loss for monitoring\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2814fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
